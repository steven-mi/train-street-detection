{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Street Situation Detection Network\n",
    "This project deals with the problem of detecting street situation images (images which are taken on the outside). The used dataset for training the network, was self-created. In order to get a copy of the dataset, contact s0558366@htw-berlin.de\n",
    "\n",
    "## Requirements\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('TensorFlow version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "IMG_HEIGHT = 299\n",
    "IMG_WIDTH = 299"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "### Training dataset\n",
    "\n",
    "The training dataset is a collection of street situations. The positive examples for a street image, were randomly selected from following datasets:\n",
    "\n",
    "- [BDD100K Dataset](https://bair.berkeley.edu/blog/2018/05/30/bdd/)\n",
    "- [Mapillary Vistas Dataset](https://www.mapillary.com/dataset/vistas?pKey=q0GhQpk20wJm1ba1mfwJmw&lat=20&lng=0&z=1.5)\n",
    "- [Cityscapes Dataset](https://www.cityscapes-dataset.com/)\n",
    "\n",
    "The negative examples were randomly selected from the [ImageNet](http://image-net.org/) validation dataset. Overall there are 12.000 images, split into a into a `train` (10.000 images) and `validation` (2000) images dataset. In each dataset the percentage of positive and negative example is 50%.#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_situation_dataset_path = \"./street-situation-dataset\"\n",
    "\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = os.path.join(street_situation_dataset_path, \"train\")\n",
    "train_data_dir = pathlib.Path(train_data_dir)\n",
    "\n",
    "train_data_gen = image_generator.flow_from_directory(directory=str(train_data_dir),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_data_dir = os.path.join(street_situation_dataset_path, \"validation\")\n",
    "val_data_dir = pathlib.Path(val_data_dir)\n",
    "\n",
    "val_data_gen = image_generator.flow_from_directory(directory=str(val_data_dir),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = \"./evaluation-images\"\n",
    "test_data_dir = pathlib.Path(test_data_dir)\n",
    "\n",
    "test_data_gen = image_generator.flow_from_directory(directory=str(test_data_dir),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for n in range(20):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.axis('off')\n",
    "image_batch, label_batch = next(train_data_gen)\n",
    "show_batch(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Street Situation Detection Network\n",
    "\n",
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    base_model = keras.applications.ResNet50V2(weights=\"imagenet\", include_top=False)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = base_model.output\n",
    "    model = keras.layers.GlobalAveragePooling2D()(model)\n",
    "    model = keras.layers.Dense(1024, activation='relu')(model)\n",
    "    \n",
    "    predictions = keras.layers.Dense(2, activation='softmax')(model)\n",
    "    return keras.models.Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('logs')\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "checkpoint_dir= os.path.join(logdir, 'model_{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cbk = keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                              write_images=True,\n",
    "                                              histogram_freq=0,  # How often to log histogram visualizations\n",
    "                                              embeddings_freq=0,  # How often to log embedding visualizations\n",
    "                                              update_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cbk = keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir,\n",
    "                                                 # Path where to save the model\n",
    "                                                 # The two parameters below mean that we will overwrite\n",
    "                                                 # the current checkpoint if and only if\n",
    "                                                 # the `val_loss` score has improved.\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tensorboard_cbk, checkpoint_cbk,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data_gen, epochs=EPOCHS, validation_data=val_data_gen,  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data_dir)\n",
    "print('\\nTest accuracy: {}'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
